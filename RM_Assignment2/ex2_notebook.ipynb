{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Engineering - Financial Engineering, FY 2024-2025\n",
    "<hr>\n",
    "\n",
    "# Risk Management - Exercise 2: Market Implied vs Historical Default Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries. The bootstrap_py package has been built in the previous assignment.\n",
    "# The utilities module contains some useful functions.\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "from utilities.ex1_utilities import business_date_offset, year_frac_act_x\n",
    "from utilities.ex2_utilities import (\n",
    "    defaultable_bond_dirty_price_from_intensity,\n",
    "    defaultable_bond_dirty_price_from_z_spread,\n",
    ")\n",
    "\n",
    "from bootstrap_py import Bootstrap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we run the bootstrap on the Market Data, using the `Bootstrap.fit()` function. In the following, it will be convient to treat `discount_factors` as a `pd.Series`, with the relevant dates as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bootstrap.from_xls(\"MktData_CurveBootstrap.xls\")\n",
    "\n",
    "dates, discount_factors = b.fit()\n",
    "discount_factors = pd.Series(discount_factors, index=dates)\n",
    "\n",
    "today = pd.Timestamp(\"2023-02-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our portofolo is made up of two corporate bonds issued by the same company, the first with $1$ year maturity and the second with $2$ years maturity. Other details on the contracts are defined in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "maturity1 = 1  # Maturity in years\n",
    "maturity2 = 2 # ERROR MATURITY IS TWO YEARS\n",
    "notional1 = 1e7\n",
    "notional2 = 1e7\n",
    "coupon_rate1 = 0.05\n",
    "coupon_rate2 = 0.06\n",
    "coupon_freq1 = 2  # Coupon frequency in payments a years\n",
    "coupon_freq2 = 2\n",
    "dirty_price1 = 100\n",
    "dirty_price2 = 102\n",
    "\n",
    "rating = \"IG\"  # Credit rating\n",
    "\n",
    "# Expiries are a pd.Timestamp object, using business_date_offset \n",
    "# we guarantee they're business days\n",
    "expiry1 = business_date_offset(today, year_offset=maturity1)\n",
    "expiry2 = business_date_offset(today, year_offset=maturity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Intensity Based Model: constant intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calibrate the intesity model to the market data, under the assumption that the intensity $\\lambda$ is constant. The recovery rate is set to $\\pi = 30\\%$. Calibratrion is done by numerically solving the equation \n",
    "\n",
    "$$\n",
    "P(\\lambda \\vert t,T) = \\hat{P}(t,T)\n",
    "$$\n",
    "\n",
    "where $P(\\lambda \\vert t,T)$ is the price of the defaultable bond according to the intensity model while $\\hat{P}$ is the actual *mid* price quoted on the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average intensity over 1y: 2.43896%\n",
      "Average intensity over 2y: 2.43377%\n",
      "Mean: 2.43637%\n"
     ]
    }
   ],
   "source": [
    "# Q1: Derive the average intensity for the two bonds\n",
    "recovery_rate = 0.3\n",
    "\n",
    "h_1y = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry1,\n",
    "        coupon_rate1,\n",
    "        coupon_freq1,\n",
    "        recovery_rate,\n",
    "        intensity[0],\n",
    "        #df,\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price1,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "h_2y = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry2,\n",
    "        coupon_rate2,\n",
    "        coupon_freq2,\n",
    "        recovery_rate,\n",
    "        intensity[0],\n",
    "        #df,\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price2,\n",
    "    x0=0.01,\n",
    ")[0]\n",
    "\n",
    "print(f\"Average intensity over {maturity1}y: {h_1y:.5%}\")\n",
    "print(f\"Average intensity over {maturity2}y: {h_2y:.5%}\")\n",
    "print(f\"Mean: {(h_1y + h_2y) / 2:.5%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the implied intesities are very close to each other. Intesities are a measure of the default probability **per unit of time**, so it makes perfectly sense for the market to price equal intensity for two bond issued by the same company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Probability of default\n",
    "\n",
    "Based on the previous calculation, we compute the default probabilities for $1$ and $2$ years. Recall that the survival probability is given by\n",
    "\n",
    "$$\n",
    "Prob(t,T) = \\exp\\Bigg\\{-\\int_t^T \\lambda(s)ds\\Bigg\\} = \\exp\\Big\\{-\\lambda(T-t)\\Big\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1y default probability: 2.40693%\n",
      "2y default probability: 4.76863%\n"
     ]
    }
   ],
   "source": [
    "# Q2: Default probability estimates\n",
    "# Survival probabilities\n",
    "\n",
    "# we take the mean of the two, since they aint exactly the same\n",
    "intesity = (h_1y+h_2y)/2\n",
    "\n",
    "surv_prob_1y = np.exp(-intesity*year_frac_act_x(today, expiry1, 365))\n",
    "surv_prob_2y = np.exp(-intesity*year_frac_act_x(today, expiry2, 365))\n",
    "\n",
    "# Defaul probabilities\n",
    "default_prob_1y = 1-surv_prob_1y\n",
    "default_prob_2y = 1-surv_prob_2y\n",
    "\n",
    "print(f\"{maturity1}y default probability: {default_prob_1y:.5%}\")\n",
    "print(f\"{maturity2}y default probability: {default_prob_2y:.5%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Z-spreads\n",
    "\n",
    "Numerically inverting the `defaultable_bond_dirty_price_from_z_spread()` method, we compute the $Z$-spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-spread over 1y: 0.01721\n",
      "Z-spread over 2y: 0.01727\n"
     ]
    }
   ],
   "source": [
    "# Q3: Z-spread calculation\n",
    "z_spread_1y = fsolve(\n",
    "    lambda z_spread: defaultable_bond_dirty_price_from_z_spread(\n",
    "        today,\n",
    "        expiry1,\n",
    "        coupon_rate1,\n",
    "        coupon_freq1,\n",
    "        z_spread[0],\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price1,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "z_spread_2y = fsolve(\n",
    "    lambda z_spread: defaultable_bond_dirty_price_from_z_spread(\n",
    "        today,\n",
    "        expiry2,\n",
    "        coupon_rate2,\n",
    "        coupon_freq2,\n",
    "        z_spread[0],\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price2,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "print(f\"Z-spread over {maturity1}y: {z_spread_1y:0.05f}\")\n",
    "print(f\"Z-spread over {maturity2}y: {z_spread_2y:0.05f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $Z$-spreads are indeed smaller than the corresponding intensities, in accordance with the theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Intensity Based Model: non-constant intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assume the intesity $\\lambda$ is no longer a constant quantity, but rather piece-wise defined\n",
    "\n",
    "$$\n",
    "\\lambda(t) = \n",
    "\\begin{cases}\n",
    "\\lambda_1 \\;\\; 0 \\leq t \\leq T_1 \\\\\n",
    "\\lambda_2 \\;\\; T_1 \\leq t \\leq T_2\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $T_1,T_2$ are the two bonds maturities.\n",
    "\n",
    "To calibrate the model, we first compute $\\lambda_1$, solving the very same equation as we did before. Then, to find $\\lambda_2$ we pass use the `fsolve()` method on the second argument of the intensity vector. The pricing function has been modified to handle non-constant intensities in the form of a `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_1y: 2.43896%\n",
      "h_1y2y: 2.42823%\n"
     ]
    }
   ],
   "source": [
    "# Q4: Default probability estimates under the hp. of piecewise constant intensity\n",
    "\n",
    "h_1y = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry1,\n",
    "        coupon_rate1,\n",
    "        coupon_freq1,\n",
    "        recovery_rate,\n",
    "        pd.Series([intensity[0]], index=[expiry1]),\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price1,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "h_1y2y = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry2,\n",
    "        coupon_rate2,\n",
    "        coupon_freq2,\n",
    "        recovery_rate,\n",
    "        pd.Series([h_1y, intensity[0]], index=[expiry1, expiry2]),\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price2,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "print(f\"h_1y: {h_1y:.5%}\")\n",
    "print(f\"h_1y2y: {h_1y2y:.5%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the calibrated intesities, we can calculate the survival probabilities using the same expression as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1y default probability: 2.40946%\n",
      "2y default probability: 4.76332%\n"
     ]
    }
   ],
   "source": [
    "surv_prob_1y = np.exp(-h_1y*year_frac_act_x(today, expiry1, 365))\n",
    "surv_prob_2y = np.exp(-(h_1y*year_frac_act_x(today, expiry1, 365) + h_1y2y*year_frac_act_x(expiry1, expiry2, 365)))\n",
    "\n",
    "\n",
    "default_prob_1y = 1-surv_prob_1y\n",
    "default_prob_2y = 1-surv_prob_2y\n",
    "\n",
    "print(f\"{maturity1}y default probability: {default_prob_1y:.5%}\")\n",
    "print(f\"{maturity2}y default probability: {default_prob_2y:.5%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce a different model to study the default probabilities on the company, based on the *Transition Matrix*. The company credit worthiness can be in three different states: Investment Grade $IG$, High Yield $HY$ and Default $DEF$. The probabilitie to transition between one class to the other is described by a Markov Chain $A$, represented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IG</th>\n",
       "      <th>HY</th>\n",
       "      <th>Def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IG</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HY</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Def</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IG    HY   Def\n",
       "IG   0.73  0.25  0.02\n",
       "HY   0.35  0.60  0.05\n",
       "Def  0.00  0.00  1.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5:Real world default probability from the rating transition matrix\n",
    "# Simplified rating transition matrix at 1y\n",
    "\n",
    "transition_matrix = pd.DataFrame(\n",
    "    [[0.73, 0.25, 0.02], [0.35, 0.6, 0.05], [0, 0, 1]],\n",
    "    index=[\"IG\", \"HY\", \"Def\"],\n",
    "    columns=[\"IG\", \"HY\", \"Def\"],\n",
    ")\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the default probability for the first and the second year. Since we know that at issue date $t=0$ the company is in state $IG$, the probability of default in one year it's given by its transition probability $\\mathbb{P}(IG \\to DEF)$. Due to the Markov property, the transitions probability for the second year are just given by the matrxi $A^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IG</th>\n",
       "      <th>HY</th>\n",
       "      <th>Def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IG</th>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.0471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HY</th>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Def</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IG      HY     Def\n",
       "IG   0.6204  0.3325  0.0471\n",
       "HY   0.4655  0.4475  0.0870\n",
       "Def  0.0000  0.0000  1.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5:Real world default probability from the rating transition matrix\n",
    "# Transitions probability for the second year\n",
    "\n",
    "transition_matrix_2y = transition_matrix @ transition_matrix\n",
    "transition_matrix_2y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One year real world default probability: 2.00%\n",
      "Two year real world default probability: 4.71%\n"
     ]
    }
   ],
   "source": [
    "# Q5:Real world default probability from the rating transition matrix\n",
    "# Default probabilities\n",
    "\n",
    "print(\n",
    "    f\"One year real world default probability: {transition_matrix.at[rating, 'Def']:.2%}\"\n",
    ")\n",
    "print(\n",
    "    f\"Two year real world default probability: {transition_matrix_2y.at[rating, 'Def']:.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scenario 1: Worsening of the credit worthiness\n",
    "\n",
    "Suppose the credit worthiness of the company drops instantanously, so that the price of the $2$ year bond drops to $97$. We execute a new intensity bootstrap to reconstruct a new $\\lambda$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_1y2y: 10.20428%\n"
     ]
    }
   ],
   "source": [
    "# Q6: Estimate the default probabilities under a shock scenario of the mid-term survival probability (Scenario1)\n",
    "# Computing the new intensities\n",
    "\n",
    "dirty_price1_shock = dirty_price1\n",
    "dirty_price2_shock = 97.0\n",
    "\n",
    "h_1y_shock = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry1,\n",
    "        coupon_rate1,\n",
    "        coupon_freq1,\n",
    "        recovery_rate,\n",
    "        intensity[0],\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price1_shock,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "h_1y2y_shock = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry2,\n",
    "        coupon_rate2,\n",
    "        coupon_freq2,\n",
    "        recovery_rate,\n",
    "        pd.Series([h_1y_shock, intensity[0]], index=[expiry1, expiry2]),\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price2_shock,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "print(f\"h_1y2y: {h_1y2y_shock:.5%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the computed intensities, we re-evalute the survival probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1y default probability: 2.40946%\n",
      "2y default probability: 11.92589%\n"
     ]
    }
   ],
   "source": [
    "# Q6: Estimate the default probabilities under a shock scenario of the mid-term survival probability (Scenario1)\n",
    "# Survival probabilities\n",
    "surv_prob_1y_shock = np.exp(-h_1y_shock*year_frac_act_x(today, expiry1, 365))\n",
    "surv_prob_2y_shock = np.exp(-(h_1y_shock*year_frac_act_x(today, expiry1, 365)+h_1y2y_shock*year_frac_act_x(expiry1, expiry2, 365)))\n",
    "\n",
    "# Defaul probabilities\n",
    "default_prob_1y_shock = 1-surv_prob_1y_shock\n",
    "default_prob_2y_shock = 1-surv_prob_2y_shock\n",
    "\n",
    "print(f\"{maturity1}y default probability: {default_prob_1y_shock:0.05%}\")\n",
    "print(f\"{maturity2}y default probability: {default_prob_2y_shock:0.05%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Scenario 2: Improvement in credit worthiness\n",
    "\n",
    "In this second scenario, we suppose the credit worthiness of the company increases, so that the prices of the two bond quoted on the market both go up: the $1$ year bond is now worth $101$, while the $2$ year bond is worth $103$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_1y: 1.00955%\n",
      "h_1y2y: 2.46549%\n"
     ]
    }
   ],
   "source": [
    "# Q7: Estimate the default probabilities under a shock scenario on overall creditworthiness (Scenario2)\n",
    "# Computing the new intensities\n",
    "\n",
    "dirty_price1_shock2 = 101.0\n",
    "dirty_price2_shock2 = 103.0\n",
    "\n",
    "h_1y_shock2 = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry1,\n",
    "        coupon_rate1,\n",
    "        coupon_freq1,\n",
    "        recovery_rate,\n",
    "        intensity[0],\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price1_shock2,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "h_1y2y_shock2 = fsolve(\n",
    "    lambda intensity: defaultable_bond_dirty_price_from_intensity(\n",
    "        today,\n",
    "        expiry2,\n",
    "        coupon_rate2,\n",
    "        coupon_freq2,\n",
    "        recovery_rate,\n",
    "        pd.Series([h_1y_shock2, intensity[0]], index=[expiry1, expiry2]),\n",
    "        discount_factors,\n",
    "        100,\n",
    "    )\n",
    "    - dirty_price2_shock2,\n",
    "    x0=0.02,\n",
    ")[0]\n",
    "\n",
    "\n",
    "print(f\"h_1y: {h_1y_shock2:.5%}\")\n",
    "print(f\"h_1y2y: {h_1y2y_shock2:.5%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1y default probability: 1.00%\n",
      "2y default probability: 3.43%\n"
     ]
    }
   ],
   "source": [
    "# Q7: Estimate the default probabilities under a shock scenario on overall creditworthiness (Scenario2)\n",
    "# Survival probabilities\n",
    "\n",
    "surv_prob_1y_shock2 = np.exp(-h_1y_shock2*year_frac_act_x(today, expiry1, 365))\n",
    "surv_prob_2y_shock2 = np.exp(-(h_1y_shock2*year_frac_act_x(today, expiry1, 365)+h_1y2y_shock2*year_frac_act_x(expiry1, expiry2, 365)))\n",
    "\n",
    "# Defaul probabilities\n",
    "default_prob_1y_shock2 = 1-surv_prob_1y_shock2\n",
    "default_prob_2y_shock2 = 1-surv_prob_2y_shock2\n",
    "\n",
    "print(f\"{maturity1}y default probability: {default_prob_1y_shock2:.2%}\")\n",
    "print(f\"{maturity2}y default probability: {default_prob_2y_shock2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Historical vs Implied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the analytical conditional probability using the exponential decay relationship between the survival probability and the derived intensity under Scenario 1 (point 6). Default probability is computed as 1 minus the survival probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Implied: 9.75139%\n",
      "Historical: 5.00000%\n"
     ]
    }
   ],
   "source": [
    "# Q8: Are the conditional default probabilities between the first and the second year derived under the scenario 1\n",
    "# consistent with the equivalent real-world probabilities derived from the transition matrix?\n",
    "\n",
    "p_market = np.exp(-h_1y2y_shock*year_frac_act_x(expiry1, expiry2, 365))\n",
    "p_hist = transition_matrix.at[\"HY\", \"Def\"]\n",
    "print(f\"Market Implied: {1-p_market:0.05%}\")\n",
    "print(f\"Historical: {p_hist:0.05%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
